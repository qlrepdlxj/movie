{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code='136990'\n",
    "test_url = \"https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=\"+code+\"&type=before&page=1\"\n",
    "resp = requests.get(test_url)\n",
    "html = BeautifulSoup(resp.content, 'html.parser')\n",
    "# html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_result = html.find('div', {'class': 'score_result'})\n",
    "lis = score_result.findAll('li')\n",
    "lis[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = lis[0].find('p').getText()\n",
    "type(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = lis[0].find('em').getText()\n",
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like = lis[0].find('div', {'class': 'btn_area'}).findAll('span')[1].getText()\n",
    "dislike = lis[0].find('div', {'class': 'btn_area'}).findAll('span')[3].getText()\n",
    "# like, dislike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nickname = lis[0].findAll('a')[0].find('span').getText()\n",
    "nickname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "created_at = datetime.strptime(lis[0].find('dt').findAll('em')[-1].getText(), \"%Y.%m.%d %H:%M\")\n",
    "# created_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url):\n",
    "    resp = requests.get(url)\n",
    "    html = BeautifulSoup(resp.content, 'html.parser')\n",
    "    score_result = html.find('div', {'class': 'score_result'})\n",
    "    lis = score_result.findAll('li')\n",
    "#     txt_list=[]\n",
    "#     time_list=[]\n",
    "#     score_list=[]\n",
    "#     movie_list=[]\n",
    "    for li in lis:\n",
    "#         list1=[]\n",
    "        nickname = li.findAll('a')[0].find('span').getText()\n",
    "        created_at = datetime.strptime(li.find('dt').findAll('em')[-1].getText(), \"%Y.%m.%d %H:%M\")\n",
    "        \n",
    "        review_text = li.find('p').getText()\n",
    "        score = li.find('em').getText()\n",
    "        btn_likes = li.find('div', {'class': 'btn_area'}).findAll('span')\n",
    "        like = btn_likes[1].getText()\n",
    "        dislike = btn_likes[3].getText()        \n",
    "        watch_movie = li.find('span', {'class':'ico_viewer'})\n",
    "        \n",
    "#         txt_list.append(review_text)\n",
    "#         time_list.append(created_at)\n",
    "#         score_list.append(score)\n",
    "#         # 간단하게 프린트만 했습니다.\n",
    "#         movie_list.append(list(zip(txt_list,time_list,score_list)))\n",
    "#         print(movie_list)\n",
    "#     data = {txt_list,time_list,score_list}\n",
    "#         df = pd.DataFrame(movie_list)\n",
    "#         df.to_csv(code+'.csv','a')\n",
    "        print(created_at, review_text, score, like, dislike, watch_movie and True or False, nickname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = html.find('div', {'class':'score_total'}).find('strong').findChildren('em')[1].getText()\n",
    "# int(result.replace(',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url = 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=119412&type=after'\n",
    "resp = requests.get(test_url)\n",
    "html = BeautifulSoup(resp.content, 'html.parser')\n",
    "result = html.find('div', {'class':'score_total'}).find('strong').findChildren('em')[1].getText()\n",
    "total_count = int(result.replace(',', ''))\n",
    "\n",
    "for i in range(1, int(total_count / 10) + 2):\n",
    "    url = test_url + '&page=' + str(i)\n",
    "#     print('url: \"' + url + '\" is parsing....')\n",
    "    get_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code='136990'\n",
    "test_url = \"https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=\"+code+\"&type=before&page=1\"\n",
    "resp = requests.get(test_url)\n",
    "html = BeautifulSoup(resp.content, 'html.parser')\n",
    "result = html.find('div', {'class':'score_total'}).find('strong').findChildren('em')[1].getText()\n",
    "total_count = int(result.replace(',', ''))\n",
    "# html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_result = html.find('div', {'class': 'score_result'})\n",
    "lis = score_result.findAll('li')\n",
    "# lis[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = lis[0].find('p').getText()\n",
    "type(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# created_at = datetime.strptime(lis[0].find('dt').findAll('em')[-1].getText()[0:10], \"%Y.%m.%d\")\n",
    "created_at = lis[0].find('dt').findAll('em')[-1].getText()[0:10]\n",
    "created_at = created_at.replace(\".\",\"\")\n",
    "created_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import multiprocessing\n",
    "\n",
    "af='after'\n",
    "be='before'\n",
    "lis = pd.read_csv('../movie_04.csv')\n",
    "movie_lis =[]\n",
    "\n",
    "for i in range(len(lis['naver_movieCd'])):\n",
    "    movie_lis.insert(i,str(lis['naver_movieCd'][i])[:-2])\n",
    "# len(movie_lis)\n",
    "\n",
    "def func11(code):\n",
    "    lists = []\n",
    "#     code=str(movie_lis[i])[:-2]\n",
    "    test_url = 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code='+code+'&type='+af+'&onlyActualPointYn=N&order=newest'\n",
    "    resp = requests.get(test_url)\n",
    "    html = BeautifulSoup(resp.content, 'html.parser')\n",
    "    result = html.find('div', {'class':'score_total'}).find('strong').findChildren('em')[1].getText()\n",
    "    total_count = int(result.replace(',', ''))\n",
    "    print(code)\n",
    "    for i in tqdm_notebook(range(1,int(total_count / 10) + 2)):\n",
    "        url = test_url + '&page=' + str(i)\n",
    "    #     print('url: \"' + url + '\" is parsing....')\n",
    "    #     get_data(url)\n",
    "        resp = requests.get(url)\n",
    "        html = BeautifulSoup(resp.content, 'html.parser')\n",
    "        score_result = html.find('div', {'class': 'score_result'})\n",
    "    #     print(score_result)\n",
    "        lis = score_result.findAll('li')\n",
    "    #     print(lis[0])\n",
    "        for li in lis:\n",
    "            a = []\n",
    "            created_at = li.find('dt').findAll('em')[-1].getText()[0:10]\n",
    "            created_at = created_at.replace(\".\",\"\")\n",
    "            score = li.find('em').getText()\n",
    "            review_text = li.find('p').getText()\n",
    "            a = [created_at, score, review_text]\n",
    "            lists.append(a)\n",
    "    \n",
    "    df = pd.DataFrame(lists)\n",
    "#     df.to_csv('../data2/'+af+'2/'+code+'.csv',index=False)\n",
    "    df.to_csv('../data2/'+af+'/'+code+'.csv',index=False)\n",
    "    \n",
    "pool = multiprocessing.Pool(processes=4)\n",
    "pool.map(func11,movie_lis)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import multiprocessing\n",
    "\n",
    "af='after'\n",
    "be='before'\n",
    "lis = pd.read_csv('../movie_04.csv')\n",
    "movie_lis =['155716','136872']\n",
    "\n",
    "# for i in range(len(lis['naver_movieCd'])):\n",
    "#     movie_lis.insert(i,str(lis['naver_movieCd'][i])[:-2])\n",
    "# len(movie_lis)\n",
    "\n",
    "def func12(code):\n",
    "    lists = []\n",
    "#     code=str(movie_lis[i])[:-2]\n",
    "    test_url = 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code='+code+'&type='+af+'&onlyActualPointYn=N&order=newest'\n",
    "    resp = requests.get(test_url)\n",
    "    html = BeautifulSoup(resp.content, 'html.parser')\n",
    "    result = html.find('div', {'class':'score_total'}).find('strong').findChildren('em')[1].getText()\n",
    "    total_count = int(result.replace(',', ''))\n",
    "    print(code)\n",
    "    for i in tqdm_notebook(range(1,int(total_count / 10) + 2)):\n",
    "        url = test_url + '&page=' + str(i)\n",
    "    #     print('url: \"' + url + '\" is parsing....')\n",
    "    #     get_data(url)\n",
    "        resp = requests.get(url)\n",
    "        html = BeautifulSoup(resp.content, 'html.parser')\n",
    "        score_result = html.find('div', {'class': 'score_result'})\n",
    "    #     print(score_result)\n",
    "        lis = score_result.findAll('li')\n",
    "    #     print(lis[0])\n",
    "        for li in lis:\n",
    "            try:\n",
    "                a = []\n",
    "                created_at = li.find('dt').findAll('em')[-1].getText()[0:10]\n",
    "                created_at = created_at.replace(\".\",\"\")\n",
    "                score = li.find('em').getText()\n",
    "                review_text = li.find('p').getText()\n",
    "                a = [created_at, score, review_text]\n",
    "                lists.append(a)\n",
    "            except AttributeError:\n",
    "                pass\n",
    "    \n",
    "    df = pd.DataFrame(lists)\n",
    "    df.to_csv('../data2/'+af+'/'+code+'.csv',index=False)\n",
    "        \n",
    "# pool = multiprocessing.Pool(processes=8)\n",
    "# pool.map(func11,movie_lis)\n",
    "# pool.close()\n",
    "# pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import multiprocessing\n",
    "\n",
    "af='after'\n",
    "be='before'\n",
    "lis = pd.read_csv('../movie_04.csv')\n",
    "j=0\n",
    "movie_lis2=[]\n",
    "for i in range(len(lis['naver_movieCd'])):\n",
    "    if(os.path.isfile('/root/movie/data2/after/'+str(lis['naver_movieCd'][i])[:-2]+'.csv') == False):\n",
    "        movie_lis2.insert(j,str(lis['naver_movieCd'][i])[:-2])\n",
    "        j+=1\n",
    "movie_lis2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(movie_lis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isfile(str(lis['naver_movieCd'][2])[:-2]+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isfile('/root/movie/data2/after/'+str(lis['naver_movieCd'][1])[:-2]+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(lis['naver_movieCd'][1])[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_lis2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(processes=8)\n",
    "pool.map(func12,movie_lis2)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import multiprocessing\n",
    "\n",
    "af='after'\n",
    "be='before'\n",
    "lis = pd.read_csv('../movie_04.csv')\n",
    "movie_lis =['155716','136872']\n",
    "\n",
    "# for i in range(len(lis['naver_movieCd'])):\n",
    "#     movie_lis.insert(i,str(lis['naver_movieCd'][i])[:-2])\n",
    "# len(movie_lis)\n",
    "code = '155716'\n",
    "def func12(code):\n",
    "    lists = []\n",
    "#     code=str(movie_lis[i])[:-2]\n",
    "    test_url = 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code='+code+'&type='+af+'&onlyActualPointYn=N&order=newest'\n",
    "    resp = requests.get(test_url)\n",
    "    html = BeautifulSoup(resp.content, 'html.parser')\n",
    "    result = html.find('div', {'class':'score_total'}).find('strong').findChildren('em')[1].getText()\n",
    "    total_count = int(result.replace(',', ''))\n",
    "    print(code)\n",
    "    for i in tqdm_notebook(range(1,int(total_count / 10) + 2)):\n",
    "        url = test_url + '&page=' + str(i)\n",
    "    #     print('url: \"' + url + '\" is parsing....')\n",
    "    #     get_data(url)\n",
    "        resp = requests.get(url)\n",
    "        html = BeautifulSoup(resp.content, 'html.parser')\n",
    "        score_result = html.find('div', {'class': 'score_result'})\n",
    "    #     print(score_result)\n",
    "        lis = score_result.findAll('li')\n",
    "    #     print(lis[0])\n",
    "        for li in lis:\n",
    "            try:\n",
    "                a = []\n",
    "                created_at = li.find('dt').findAll('em')[-1].getText()[0:10]\n",
    "                created_at = created_at.replace(\".\",\"\")\n",
    "                score = li.find('em').getText()\n",
    "                review_text = li.find('p').getText()\n",
    "                a = [created_at, score, review_text]\n",
    "                lists.append(a)\n",
    "            except AttributeError:\n",
    "                pass\n",
    "func12(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
